{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c2a139-3daf-4cb7-874c-9e18e7d256a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fe5dd43b4b4082acfc4011434f05e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4e680-c7ee-4175-aa23-3a5d8a390677",
   "metadata": {},
   "source": [
    "# Do not run the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80637fd5-6461-4223-a859-46043f014446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For PDF's\n",
    "import os\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "\n",
    "def read_pdf_file(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "data_folder = 'Contract'  # Replace with the path to your folder containing PDF and TXT files\n",
    "\n",
    "# List all files in the data folder\n",
    "all_files = [f for f in os.listdir(data_folder)]\n",
    "\n",
    "# Filter PDF files\n",
    "pdf_files = [f for f in all_files if f.endswith('.pdf')]\n",
    "\n",
    "# Create lists to store filename and content\n",
    "filename_list = []\n",
    "content_list = []\n",
    "\n",
    "# Read content from each PDF file and collect filename (without .pdf extension) and content in lists\n",
    "for pdf_file in pdf_files:\n",
    "    file_path = os.path.join(data_folder, pdf_file)\n",
    "    content = read_pdf_file(file_path)\n",
    "    filename_without_extension = os.path.splitext(pdf_file)[0]\n",
    "    filename_list.append(filename_without_extension)\n",
    "    content_list.append(content)\n",
    "\n",
    "# Create a dictionary with 'filename' and 'content' as keys and their respective lists as values\n",
    "data = {\n",
    "    'Contract_type': filename_list,\n",
    "    'Response': content_list\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('Contract_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8cd6a-f6a1-497b-860a-aa438b739744",
   "metadata": {},
   "source": [
    "# Do not run the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "660f0378-3dac-4057-97d5-c96d79a81aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Contract_type                                           Response  \\\n",
      "0        Agreement_6_28_07  1 \\n \\nMUTUAL CONFIDENTIAL & NON-DISCLOSURE AG...   \n",
      "1                    nda_2  NON – DISCLOSURE AGREEMENT  \\n     This agreem...   \n",
      "2  Non-Disclosure-SmartCMS   NON -DISCLOSURE AGREEMENT  \\n  \\n \\nIHiS Proc...   \n",
      "3    nda-employee-template  Non-disclosure Agreement – v. 1.0  \\n Non-Disc...   \n",
      "4  Evelozcity%20OESA%20NDA  NON- DISCLOSURE AGREEMENT  \\n \\n This NON- DIS...   \n",
      "\n",
      "                                                text  \n",
      "0  Below is an instruction that describes a topic...  \n",
      "1  Below is an instruction that describes a topic...  \n",
      "2  Below is an instruction that describes a topic...  \n",
      "3  Below is an instruction that describes a topic...  \n",
      "4  Below is an instruction that describes a topic...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Contract_dataset.csv\")\n",
    "\n",
    "text_col = []\n",
    "for _, row in df.iterrows():\n",
    "    prompt = \"Below is an instruction that describes a topic, task is to write contract, paired with an response complete the request.\\n\\n\"\n",
    "    instructions = str(row[\"Contract_type\"])\n",
    "    response = str(row[\"Response\"])\n",
    "    \n",
    "    text = prompt + \"###Instruction:\\n\" + instructions + \"\\n### Response\" + response\n",
    "    \n",
    "    text_col.append(text)\n",
    "    \n",
    "df.loc[:, \"text\"] = text_col\n",
    "print(df.head())\n",
    "df.to_csv(\"train.csv\", index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72752288-900b-40aa-9f4d-175aa8095a64",
   "metadata": {},
   "source": [
    "# Start running from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933d492c-e06c-4d96-a9ab-867ef3f3bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229b02c3-0c76-42fd-a699-c2e625c9cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba278d95-2fb1-4fa2-b766-17f848b2fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-2-13b-hf\"\n",
    "new_model = \"llama-2-7b-ft\"\n",
    "lora_r = 64\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "use_4bit = True\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "use_nested_quant = False\n",
    "output_dir = \"./Contract_weights/results\"\n",
    "num_train_epochs = 2 \n",
    "fp16 = False \n",
    "bf16 = True \n",
    "per_device_train_batch_size = 2\n",
    "per_device_eval_batch_size = 2\n",
    "gradient_accumulation_steps = 2\n",
    "gradient_checkpointing = True\n",
    "max_grad_norm = 1 \n",
    "learning_rate = 5e-6\n",
    "weight_decay = 0 \n",
    "optim = \"adamw_hf\"\n",
    "lr_scheduler_type = \"constant\"\n",
    "max_steps = -1 \n",
    "warmup_ratio = 0.0 \n",
    "group_by_length = True\n",
    "save_steps = 10\n",
    "logging_steps = 1\n",
    "max_seq_length = 3000 \n",
    "packing = False\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ac357-b536-48e0-8081-17b31efadeba",
   "metadata": {},
   "source": [
    "# Do not run below code unless you want to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e0c32f-165a-4904-9316-72caa038ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\",\n",
    "    push_to_hub_organization = \"huggingface\",\n",
    "    push_to_hub_token=\"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\"\n",
    ")\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ec34a-d6d5-4be0-b768-69f4e1b0d3ab",
   "metadata": {},
   "source": [
    "# Run below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d292cd8c-c3f0-4c8c-96cd-8fcde82627e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a16bd8c83846d8b9b412972827c210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, output_dir)\n",
    "model = model.merge_and_unload()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b00ca2e4-2531-4b11-b4f7-1e9f1ac63895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 13 17:38:45 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    55W / 400W |  26985MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    982190      C   /usr/bin/python3                26982MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7504bb0b-627d-4b7d-a9aa-237455b585f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "generate_text = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    return_full_text=True, \n",
    "    task='text-generation',\n",
    "    temperature=0.5, \n",
    "    max_new_tokens=512,\n",
    "    repetition_penalty=1.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9780687f-c3b4-4768-b786-7c2ff8b42051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c96ddbc-e4bd-430c-b6bc-50027f2b9a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[INST] <<SYS>>\\nPlease do not write anything about this conversation with anyone else. This includes but is not limited to: friends, family members, coworkers, etc. You may only discuss it with people who have signed their own NDAs.\\n\\nThank you!\\n<</SYS>>\\nI am going to be working on some sensitive projects at work. I need to sign an NDA before starting. Can you draft one?\\n\\n[INST] <<SYS>>\\nOf course! What kind of project will you be working on?\\n\\n[USER] <@user>\\nIt involves AI research. We want to keep our results secret until we publish them.\\n\\n[INST] <<SYS>>\\nOkay, here is what I came up with:\\n\\n**Name:** John Doe\\n\\n**Company Name:** ABC Inc.\\n\\n**Position:** Software Engineer\\n\\n**Date:** January 1st, 2023\\n\\n**Purpose:** To protect confidential information related to artificial intelligence research conducted by ABC Inc.\\n\\n**Confidential Information:** All data, documents, software code, algorithms, models, ideas, concepts, inventions, discoveries, trade secrets, techniques, processes, methods, designs, drawings, specifications, reports, proposals, financial information, customer lists, marketing plans, business strategies, pricing policies, product development plans, manufacturing processes, sales forecasts, cost data, profitability analyses, personnel records, and other proprietary information relating to the Company’s activities, including without limitation all such information developed or acquired during the Employee’s employment with the Company.\\n\\n**Non-Disclosure Obligation:** The Employee agrees to maintain the Confidential Information in strict confidence and shall not disclose the same to any person or entity outside of the Company except as expressly authorized by the Company in writing. The Employee further agrees not to use the Confidential Information for his/her benefit or for the benefit of others.\\n\\n**Exceptions:** The obligations set forth above shall not apply to any information which (a) was known to the Employee prior to its disclosure; (b) becomes public knowledge through no fault of the Employee; (c) is rightfully received from third parties without restriction regarding disclosure; or (d)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt= f\"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "Write me an NDA for an employee in my company\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f4ac147-0201-48d8-babb-e73475925065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea459f1208a4586aaa6e3f2b175c93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00003-of-00003.bin:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731324cc7afa4eff8c4cb72e8d1a65f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00003.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa02b910feba4a6b96253623463241b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00003.bin:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b735fa2ee3a249128cbcd5d2e5a59c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af341791ded84895bedca1bec202c4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/myparalegal/Contracts/commit/5d0b10d78e2d25c1fc06ac53cb8d6fd834c20b7a', commit_message='Upload tokenizer', commit_description='', oid='5d0b10d78e2d25c1fc06ac53cb8d6fd834c20b7a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"Contracts\")\n",
    "tokenizer.push_to_hub(\"Contracts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acf7dc2-9823-4f53-b61d-d57b06cfc5c5",
   "metadata": {},
   "source": [
    "# Run the following code cells for inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7f33ff2-f421-49b3-a1f8-5786f16a3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://wgbq2iec83cc17j7.us-east-1.aws.endpoints.huggingface.cloud\"\n",
    "HUGGINGFACE_TOKEN = \"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\"\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {HUGGINGFACE_TOKEN}\"}\n",
    "\n",
    "prompt = f\"\"\"<s>[INST] <<SYS>>\n",
    "Below is an instruction that describes a topic, task is to write contract, paired with an response complete the request.\\n\\n\n",
    "<</SYS>>\n",
    "Write me a 3511 standard NDA\n",
    "[INST]\n",
    "\"\"\"\n",
    "\n",
    "payload = {\"inputs\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fde645d-f1a6-474a-802d-31e87758c8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.7 ms, sys: 1.73 ms, total: 21.4 ms\n",
      "Wall time: 51.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import requests\n",
    "\n",
    "resp = requests.post(API_URL, json=payload, headers=headers)\n",
    "response = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "127f9d32-1d4e-4140-a970-0a642e8f0182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<</NDA-02>><<NONDISCLOSURE_AGREEMENT>>\\nThis Non Disclosure Agreement (the \"Agreement\") dated as of ________________, by and between:\\n___________________ (\"Disclosing Party\"), whose address for notice purposes shall be at _________________________________________________________________________________;and\\n___________________(\"Receiving Party\"). The parties agree as follows:\\nWHEREAS, Receiving party desires access to certain confidential information relating to products or services offered by disclosing party in order to evaluate such offerings on behalf of itself or its affiliates(collectively referred herein as “receiver”);AND WHEREAS,discloser has agreed to disclose Confidential Information subject to this agreement’s terms & conditions ;NOW THEREFORE IN CONSIDERATION OF THE FOREGOING AND FOR OTHER GOOD AND VALUABLE CONSIDERATION RECEIVED BY EACH PARTY HERETO,THE DISCLOSED SHALL KEEP ALL SUCH MATTERS AS ABOVE DESCRIBED TO IT OR ITS AGENTS COMPLETELY SECRET FROM ANYONE EXCEPT ONES AUTHORIZED UNDER WRITEN APPROVAL.THIS IS NOT INTEND TO BE BINDINNG UPON US UNLESS SIGNED BY YOU WITHIN TIME FRAME SET OUT AT END OF DOCUMENT..IF NO RESPONSE THEN DEAL CANNOT PROGRESSFURTHER...BY SUBMITTING DATA /INFO VIRTUE OF WHICH MAKES ME LIABILIITY IF LEAKAGE CAUSE LOSS...SO PLZ GIVE SERIOUS HEADSPACE..BECAUSE MY CLIENT NEVER LOST TRUST SO FAIRNESS SAKE....PLZ GET BACK QUOTE.........'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cccd67-54d8-4b3c-88b4-29d4999cf0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
